{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.47503431828714726\n",
      "Standard Deviation : 0.3731182702162206\n",
      "Accuracy Score: 0.5274379884471627\n",
      "MSE: 7089.948769195536\n",
      "SCC: 0.29541173673652166\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "f1_scores = []\n",
    "accuracies = []\n",
    "mses = []\n",
    "sccs = []\n",
    "\n",
    "\n",
    "dataset1 = pd.read_csv('ccl_feature_original.csv')\n",
    "X1 = dataset1.iloc[:, 10].values.reshape(-1, 1)  \n",
    "Y1 = dataset1.iloc[:, 8].values \n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X1, Y1, random_state=0, test_size=0.2)\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "X_train_scaled1 = scaler1.fit_transform(X_train1)\n",
    "X_test_scaled1 = scaler1.transform(X_test1)\n",
    "\n",
    "Y_train_categorical1 = pd.cut(Y_train1, bins=5, labels=False)\n",
    "Y_test_categorical1 = pd.cut(Y_test1, bins=5, labels=False)\n",
    "\n",
    "classifier1 = KNeighborsClassifier(n_neighbors=15, p=2, metric='euclidean')\n",
    "classifier1.fit(X_train_scaled1, Y_train_categorical1)\n",
    "\n",
    "y_pred_categorical1 = classifier1.predict(X_test_scaled1)\n",
    "conf1 = confusion_matrix(Y_test_categorical1, y_pred_categorical1)\n",
    "f1_1 = f1_score(Y_test_categorical1, y_pred_categorical1, average='weighted')\n",
    "accuracy1 = accuracy_score(Y_test_categorical1, y_pred_categorical1)\n",
    "\n",
    "regressor1 = KNeighborsRegressor(n_neighbors=15, p=2, metric='euclidean')\n",
    "regressor1.fit(X_train_scaled1, Y_train1)\n",
    "\n",
    "y_pred1 = regressor1.predict(X_test_scaled1)\n",
    "mse1 = mean_squared_error(Y_test1, y_pred1)\n",
    "scc1, _ = spearmanr(Y_test1, y_pred1)\n",
    "\n",
    "f1_scores.append(f1_1)\n",
    "accuracies.append(accuracy1)\n",
    "mses.append(mse1)\n",
    "sccs.append(scc1)\n",
    "\n",
    "\n",
    "dataset2 = pd.read_csv('ccl_feature.csv')\n",
    "X2 = dataset2.iloc[:, 10].values.reshape(-1, 1)  \n",
    "Y2 = dataset2.iloc[:, 8].values \n",
    "X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X2, Y2, random_state=0, test_size=0.2)\n",
    "\n",
    "scaler2 = StandardScaler()\n",
    "X_train_scaled2 = scaler2.fit_transform(X_train2)\n",
    "X_test_scaled2 = scaler2.transform(X_test2)\n",
    "\n",
    "Y_train_categorical2 = pd.cut(Y_train2, bins=5, labels=False)\n",
    "Y_test_categorical2 = pd.cut(Y_test2, bins=5, labels=False)\n",
    "\n",
    "classifier2 = KNeighborsClassifier(n_neighbors=15, p=2, metric='euclidean')\n",
    "classifier2.fit(X_train_scaled2, Y_train_categorical2)\n",
    "\n",
    "y_pred_categorical2 = classifier2.predict(X_test_scaled2)\n",
    "conf2 = confusion_matrix(Y_test_categorical2, y_pred_categorical2)\n",
    "f1_2 = f1_score(Y_test_categorical2, y_pred_categorical2, average='weighted')\n",
    "accuracy2 = accuracy_score(Y_test_categorical2, y_pred_categorical2)\n",
    "\n",
    "regressor2 = KNeighborsRegressor(n_neighbors=15, p=2, metric='euclidean')\n",
    "regressor2.fit(X_train_scaled2, Y_train2)\n",
    "\n",
    "y_pred2 = regressor2.predict(X_test_scaled2)\n",
    "mse2 = mean_squared_error(Y_test2, y_pred2)\n",
    "scc2, _ = spearmanr(Y_test2, y_pred2)\n",
    "\n",
    "f1_scores.append(f1_2)\n",
    "accuracies.append(accuracy2)\n",
    "mses.append(mse2)\n",
    "sccs.append(scc2)\n",
    "\n",
    "\n",
    "dataset3 = pd.read_csv('drug_embedding.csv')\n",
    "X3 = dataset3.iloc[:, 10].values.reshape(-1, 1)  # Features\n",
    "Y3 = dataset3.iloc[:, 8].values  # Labels\n",
    "X_train3, X_test3, Y_train3, Y_test3 = train_test_split(X3, Y3, random_state=0, test_size=0.2)\n",
    "\n",
    "scaler3 = StandardScaler()\n",
    "X_train_scaled3 = scaler3.fit_transform(X_train3)\n",
    "X_test_scaled3 = scaler3.transform(X_test3)\n",
    "\n",
    "Y_train_categorical3 = pd.cut(Y_train3, bins=5, labels=False)\n",
    "Y_test_categorical3 = pd.cut(Y_test3, bins=5, labels=False)\n",
    "\n",
    "classifier3 = KNeighborsClassifier(n_neighbors=15, p=2, metric='euclidean')\n",
    "classifier3.fit(X_train_scaled3, Y_train_categorical3)\n",
    "\n",
    "y_pred_categorical3 = classifier3.predict(X_test_scaled3)\n",
    "conf3 = confusion_matrix(Y_test_categorical3, y_pred_categorical3)\n",
    "f1_3 = f1_score(Y_test_categorical3, y_pred_categorical3, average='weighted')\n",
    "accuracy3 = accuracy_score(Y_test_categorical3, y_pred_categorical3)\n",
    "\n",
    "regressor3 = KNeighborsRegressor(n_neighbors=15, p=2, metric='euclidean')\n",
    "regressor3.fit(X_train_scaled3, Y_train3)\n",
    "\n",
    "y_pred3 = regressor3.predict(X_test_scaled3)\n",
    "mse3 = mean_squared_error(Y_test3, y_pred3)\n",
    "scc3, _ = spearmanr(Y_test3, y_pred3)\n",
    "\n",
    "f1_scores.append(f1_3)\n",
    "accuracies.append(accuracy3)\n",
    "mses.append(mse3)\n",
    "sccs.append(scc3)\n",
    "\n",
    "\n",
    "f1 = np.mean(f1_scores)\n",
    "std = np.std(f1_scores)\n",
    "accuracy = np.mean(accuracies)\n",
    "mse = np.mean(mses)\n",
    "scc = np.mean(sccs)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Standard Deviation :\", std)\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"SCC:\", scc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain:\n",
      "Feature 1: 0.7420273736041478\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "\n",
    "# Concatenate features and target variables from all datasets\n",
    "X_combined = np.concatenate((X1, X2, X3), axis=0)\n",
    "Y_combined = np.concatenate((Y1, Y2, Y3), axis=0)\n",
    "\n",
    "# Define a function to calculate information gain\n",
    "def calculate_information_gain(X, y):\n",
    "    # Check if the target variable y is categorical or continuous\n",
    "    if len(np.unique(y)) > 5:  # If the number of unique values in y is greater than 5, it's a regression task\n",
    "        return mutual_info_regression(X, y)\n",
    "    else:  # Otherwise, it's a classification task\n",
    "        return mutual_info_classif(X, y)\n",
    "\n",
    "# Calculate information gain for the combined dataset\n",
    "information_gain_combined = calculate_information_gain(X_combined, Y_combined)\n",
    "\n",
    "# Display information gain scores for each feature\n",
    "print(\"Information Gain:\")\n",
    "for i, info_gain in enumerate(information_gain_combined):\n",
    "    print(f\"Feature {i+1}: {info_gain}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
